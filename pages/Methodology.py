import streamlit as st

st.set_page_config(
    page_title="Methodology â€“ Transformation Management Assistant",
    page_icon="ğŸ§ª",
    layout="wide",
)

# Guard: respect login from main app
if not st.session_state.get("authenticated", False):
    st.warning("ğŸ”’ Please log in from the main page to access this content.")
    st.stop()

st.title("ğŸ§ª Methodology & Technical Approach")
st.markdown("---")

st.subheader("1. Design Principles")
st.markdown(
    """
The Transformation Management Assistant is built around four principles:

1. **Privacy by design** â€“ Only user-pasted text is processed in this prototype.  
2. **Low friction** â€“ A simple, tab-based interface for different analysis types.  
3. **Explainability** â€“ Outputs are plain-language narratives mapped to known frameworks.  
4. **Safety & guardrails** â€“ Limited action surface (analysis-only), secure key handling, and scoped prompts.  
"""
)

st.markdown("---")

# Architecture & stack
st.subheader("2. System Architecture (High-Level)")

col1, col2 = st.columns(2)

with col1:
    st.markdown(
        """
**Technology Stack**

- ğŸ **Python** as the core language  
- ğŸ“Š **Streamlit** for the web UI and session management  
- ğŸ¤– **OpenAI** Python SDK for LLM access  
- ğŸ”‘ **Streamlit Secrets** (`secrets.toml`) for `OPENAI_API_KEY`  
- ğŸ§  `st.session_state` for:
  - Authentication flag  
  - Logged-in username  
  - Per-session analysis history  
"""
    )

with col2:
    st.markdown(
        """
**Key Components**

- `app.py`  
  - Login and authentication  
  - Main analysis interface with four tabs  
- `pages/01_About_Us.py`  
  - Project scope, objectives, data sources, and features  
- `pages/02_Methodology.py`  
  - Data flows, implementation details, and use case flowcharts  
"""
    )

st.markdown("#### High-Level Request Flow")
st.code(
    """
[User Browser] â†’ [Streamlit App] â†’ [OpenAI API] â†’ [Streamlit App] â†’ [User Browser]
    """,
    language="text",
)

st.markdown("---")

# Prompt design
st.subheader("3. Prompt Design & Lightweight Prompt Chaining")

st.markdown(
    """
The core logic sits in a single helper function: `analyze_transformation_data(user_input, analysis_type)`.

Each **analysis type** maps to a **specialised system prompt**:

- `risk_detection` â†’ transformation risk expert  
- `change_guidance` â†’ change management consultant  
- `team_analysis` â†’ team dynamics and sentiment analyst  
- `recommendations` â†’ strategic transformation advisor  

For every user request:

1. The app selects the appropriate **system prompt** based on the active tab.  
2. The userâ€™s text input (and optional parameters like framework or urgency) are appended.  
3. The combined prompt is sent to the **Chat Completions API** (`client.chat.completions.create`).  
4. The response is parsed and displayed, and stored in **`chat_history`** in `st.session_state`.  

This approach is a lightweight form of **prompt chaining / orchestration**: user choices (tab, framework, urgency) steer the model behaviour without exposing agents or tools.
"""
)

st.markdown("---")

# Use Case 1 â€“ Risk Detection flowchart
st.subheader("4. Use Case 1 â€“ Risk Detection & Early Warning (Flowchart)")

st.markdown("**Objective:** Help transformation leads detect risks ~2â€“3 weeks early from qualitative project updates.")

st.markdown("##### Textual Flowchart (for Slide 13â€“15 Style Diagrams)")

st.markdown(
    """
**Actors:**  
- ğŸ‘¤ *User*  
- ğŸ–¥ï¸ *Streamlit App*  
- ğŸ¤– *LLM (OpenAI)*  

**Step-by-step Flow:**

1. **User Login**  
   - User logs in on `app.py` using a username/password.  
   - On success, `st.session_state.authenticated = True`.

2. **Select Use Case**  
   - User clicks on the **â€œğŸ” Risk Detectionâ€** tab.

3. **Provide Input**  
   - User pastes project status updates, meeting summaries, or email snippets into the text area.

4. **Validation (Streamlit App)**  
   - Check that:
     - Input text is not empty  
     - `OPENAI_API_KEY` is available in `st.secrets`  

5. **Prompt Construction (Streamlit App)**  
   - Select the `risk_detection` system prompt:
     - Role: â€œtransformation management expert specializing in risk detectionâ€  
     - Instruction: look for risks, early warnings, and patterns  
   - Combine system prompt + user input.

6. **LLM Request (Streamlit App â†’ OpenAI)**  
   - Call `client.chat.completions.create(model="gpt-4", ...)`.

7. **Model Processing (LLM)**  
   - The model analyses the text and returns:
     - Key risks and weak signals  
     - Possible root causes  
     - Suggested mitigation actions  

8. **Response Handling (Streamlit App)**  
   - Extract the text response.  
   - Append to `st.session_state.chat_history` with:
     - Timestamp  
     - Analysis type (â€œRisk Detectionâ€)  
     - Input (truncated)  
     - Output (full).

9. **Display to User**  
   - Show under **â€œğŸ¯ Risk Analysis Resultsâ€** with clear headings or bullet points.

10. **Error Handling**  
    - If rate limits / quota / invalid key issues occur, show friendly messages like:
      - â€œâš ï¸ Rate limit exceededâ€¦â€  
      - â€œâš ï¸ Insufficient API creditsâ€¦â€  
"""
)

st.markdown("---")

# Use Case 2 â€“ Team Dynamics & Change Guidance flowchart
st.subheader("5. Use Case 2 â€“ Team Dynamics & Change Guidance (Flowchart)")

tab_team, tab_change = st.tabs(["ğŸ‘¥ Team Communication Analysis", "ğŸ“‹ Change Management Guidance"])

with tab_team:
    st.markdown("**Objective:** Understand team sentiment, resistance, and collaboration patterns from communications.")
    st.markdown(
        """
**Actors:**  
- ğŸ‘¤ *User*  
- ğŸ–¥ï¸ *Streamlit App*  
- ğŸ¤– *LLM (OpenAI)*  

**Flow Steps:**

1. User logs in and selects the **â€œğŸ‘¥ Team Analysisâ€** tab.  
2. User pastes emails, chat logs, or retrospective notes into the text area.  
3. App validates that:
   - Input is present  
   - API key is configured  

4. App selects the `team_analysis` system prompt:
   - Focus on sentiment, engagement, resistance, and collaboration.  

5. App calls the Chat Completions API with system + user messages.  
6. LLM returns analysis:
   - Overall sentiment  
   - Positive signals  
   - Areas of concern / resistance themes  
7. App displays the output as â€œğŸ‘¥ Team Dynamics Insightsâ€ and stores it in `chat_history`.  
"""
    )

with tab_change:
    st.markdown("**Objective:** Translate people challenges into practical, framework-based actions.")
    st.markdown(
        """
**Actors:**  
- ğŸ‘¤ *User*  
- ğŸ–¥ï¸ *Streamlit App*  
- ğŸ¤– *LLM (OpenAI)*  

**Flow Steps:**

1. User logs in and selects the **â€œğŸ“‹ Change Guidanceâ€** tab.  
2. User describes the change challenge (e.g. low adoption, resistant managers).  
3. User optionally chooses a **preferred framework**:
   - Auto-select, ADKAR, Kotterâ€™s 8-Step, Prosci, McKinsey 7-S.  

4. App constructs the input:
   - Base system prompt: `change_guidance`.  
   - If a framework is selected, append  
     `"Preferred framework: <framework>"` to the user message.  

5. App sends the combined prompt to the LLM via the Chat Completions API.  
6. LLM returns:
   - Short diagnosis (e.g. which dimensions are weak)  
   - Actionable recommendations aligned to the chosen framework.  

7. App displays the output under **â€œğŸ“š Best Practice Guidanceâ€** and stores it in `chat_history`.  
"""
    )

st.markdown("---")

# Safeguards & prompt injection
st.subheader("6. Safeguards, Prompt Injection & Risk Management")

st.markdown(
    """
Although this is a prototype, several safeguards are already applied:

1. **Login & Access Control**  
   - Access requires username/password; credentials are s
